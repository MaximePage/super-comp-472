{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59567d2-896b-44e2-a696-2b4a12d01b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "271423f5-f64c-47a6-9ad5-0df04a96a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction indexing for classes\n",
    "def select_class_index(labels, n):\n",
    "    labels = np.array(labels)\n",
    "    selected = []\n",
    "\n",
    "    for c in range(10):\n",
    "        idx = np.where(labels == c)[0][:n]\n",
    "        selected.extend(idx)\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06cc0b5-1c77-445d-9f8a-ff3f6e036f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1000\n",
      "5000\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# load in cifar-10 dataset\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"F:/CIFAR10_Project/data\", train=True, download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root=\"F:/CIFAR10_Project/data\", train=False, download=True)\n",
    "\n",
    "# select the first 500 train images per class\n",
    "train_indices = select_class_index(train_set.targets, 500)\n",
    "train_subset = torch.utils.data.Subset(train_set, train_indices)\n",
    "\n",
    "# select the first 100 test images\n",
    "test_indices = select_class_index(test_set.targets, 100)\n",
    "test_subset = torch.utils.data.Subset(test_set, test_indices)\n",
    "\n",
    "print(len(train_subset))  # Should be 500 * 10 = 5000\n",
    "print(len(test_subset))   # Should be 1000\n",
    "\n",
    "print(len(train_indices))  # 5000\n",
    "print(set([train_set.targets[i] for i in train_indices])) # check how many classes ( should be 0-9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da48075b-f9b0-4cca-b9a7-1353501ab22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize to 224x224x3\n",
    "transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf4e03d-8992-49ae-b64d-39a3c220b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dataloaders to hold the resized images\n",
    "\n",
    "train_subset.dataset.transform = transform_resnet\n",
    "test_subset.dataset.transform = transform_resnet\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c03d2e4-e8f4-4e47-8d72-f5b2d7c2841b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load RestNet-18 and remove the last layer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "resnet = resnet18(weights=weights)\n",
    "resnet.fc = nn.Identity() # last layer removed\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8e910a-fe0e-42af-8554-4a6f8c000279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet-18 feature extractor\n",
    "#def extract_features(dataset):\n",
    "   # loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "def extract_features(dataset, batch_size=64):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    feats = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, lbls in loader:\n",
    "            images = images.to(device)\n",
    "            f = resnet(images)\n",
    "            feats.append(f.cpu())\n",
    "            labels.append(lbls)\n",
    "\n",
    "    return torch.cat(feats), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5a8d1d-ef1b-4ed8-98b4-cea29d47b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features, train_labels = extract_features(train_subset.dataset)\n",
    "#test_features, test_labels = extract_features(test_subset.dataset)\n",
    "train_features, train_labels = extract_features(train_subset)\n",
    "test_features, test_labels = extract_features(test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1c1665f-d97a-49f2-86b1-4e1bed480a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 50) (1000, 50)\n"
     ]
    }
   ],
   "source": [
    "# TypeError: can't convert cuda:0 device type tensor to numpy. \n",
    "# Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "\n",
    "train_features_np = train_features.cpu().numpy()\n",
    "test_features_np = test_features.cpu().numpy()\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "train_pca = pca.fit_transform(train_features_np)\n",
    "test_pca  = pca.transform(test_features_np)\n",
    "\n",
    "print(train_pca.shape, test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed40897-f0c1-4900-a159-23d014677f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Linear(50, 512)- ReLU- Linear(512, 512)- BatchNorm(512)- ReLU- Linear(512, 10)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(50, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f14f3e2-13f1-4282-a9ca-ce014100692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer mlp variant\n",
    "\n",
    "class MLP_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(50, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0666924f-2bc3-45b0-8ccb-7513b057ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer mlp variant\n",
    "\n",
    "class MLP_4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(50, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475f2ada-f97e-4631-9a8f-4198a33ef707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\AppData\\Local\\Temp\\ipykernel_7708\\4204448965.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(train_labels, dtype=torch.long)\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp\\ipykernel_7708\\4204448965.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(test_labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "#pytorch tensors\n",
    "\n",
    "X_train = torch.tensor(train_pca, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(test_pca, dtype=torch.float32)\n",
    "y_test = torch.tensor(test_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ee4336-312e-44ab-97f2-e10ba480b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset  = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b71c2d-13d7-4d4b-9b75-29c05f018296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should use the cross-entropy loss torch.nn.CrossEntropyLoss for training. \n",
    "# Also, use the SGD optimizer with momentum=0.9.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b600b95-16e7-481c-b368-5b628f46fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model\n",
    "\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "118dda32-8c11-421a-9da6-dc32157e350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collects predicted and true labels\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            out = model(X)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12d2ce4a-b519-4a6e-b317-49024809c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_loop_full(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            out = model(X)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68e77d07-26cf-414f-9fcb-8ff364f19b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.7596 | Test Accuracy: 81.30%\n",
      "Epoch 02 | Loss: 0.4129 | Test Accuracy: 82.70%\n",
      "Epoch 03 | Loss: 0.3289 | Test Accuracy: 83.70%\n",
      "Epoch 04 | Loss: 0.2673 | Test Accuracy: 83.50%\n",
      "Epoch 05 | Loss: 0.2257 | Test Accuracy: 82.70%\n",
      "Epoch 06 | Loss: 0.1737 | Test Accuracy: 83.10%\n",
      "Epoch 07 | Loss: 0.1356 | Test Accuracy: 82.30%\n",
      "Epoch 08 | Loss: 0.1153 | Test Accuracy: 83.10%\n",
      "Epoch 09 | Loss: 0.0854 | Test Accuracy: 82.30%\n",
      "Epoch 10 | Loss: 0.0662 | Test Accuracy: 82.30%\n",
      "Epoch 11 | Loss: 0.0585 | Test Accuracy: 82.10%\n",
      "Epoch 12 | Loss: 0.0431 | Test Accuracy: 82.80%\n",
      "Epoch 13 | Loss: 0.0526 | Test Accuracy: 81.60%\n",
      "Epoch 14 | Loss: 0.0463 | Test Accuracy: 82.30%\n",
      "Epoch 15 | Loss: 0.0499 | Test Accuracy: 83.00%\n",
      "Epoch 16 | Loss: 0.0318 | Test Accuracy: 82.10%\n",
      "Epoch 17 | Loss: 0.0312 | Test Accuracy: 82.70%\n",
      "Epoch 18 | Loss: 0.0229 | Test Accuracy: 82.70%\n",
      "Epoch 19 | Loss: 0.0259 | Test Accuracy: 81.40%\n",
      "Epoch 20 | Loss: 0.0280 | Test Accuracy: 82.10%\n"
     ]
    }
   ],
   "source": [
    "#actual training\n",
    "\n",
    "for epoch in range(20):  # 20 is apparently good for 5k samples\n",
    "    train_loss = train(model, train_loader)\n",
    "    acc = evaluate(model, test_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {train_loss:.4f} | Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "863efac6-2dce-4059-87d3-f4a27d928ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of three-layer MLP:\n",
      "Accuracy: 0.821\n",
      "Precision: 0.8229314736500685\n",
      "Recall : 0.8210000000000001\n",
      "F1-score : 0.8206237678140541\n",
      "Confusion Matrix:\n",
      " [[79  2  6  2  1  0  1  1  4  4]\n",
      " [ 3 90  0  1  0  0  0  0  1  5]\n",
      " [ 5  0 82  5  2  1  4  1  0  0]\n",
      " [ 0  0  3 72  1 13  6  4  1  0]\n",
      " [ 3  0  6  6 70  2  3 10  0  0]\n",
      " [ 1  1  6 13  3 71  3  2  0  0]\n",
      " [ 1  0  3  2  1  3 88  2  0  0]\n",
      " [ 0  0  1  3  3  3  0 90  0  0]\n",
      " [ 5  1  1  1  0  0  0  1 90  1]\n",
      " [ 2  6  0  1  1  0  0  0  1 89]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='macro'))\n",
    "    print(\"Recall :\", recall_score(y_true, y_pred, average='macro'))\n",
    "    print(\"F1-score :\", f1_score(y_true, y_pred, average='macro'))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"Evaluation of three-layer MLP:\")\n",
    "y_true, y_pred = evaluation_loop_full(model, test_loader, device)\n",
    "evaluate_model(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07720d9b-98ce-47b3-91b9-44b094d25570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 3-layer MLP model\n",
    "\n",
    "torch.save(model, \"MLP_3_saved.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f42050a-53cf-4f33-8e9c-6a2c65852cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.7924 | Test Accuracy: 81.00%\n",
      "Epoch 02 | Loss: 0.4473 | Test Accuracy: 82.70%\n",
      "Epoch 03 | Loss: 0.3788 | Test Accuracy: 83.50%\n",
      "Epoch 04 | Loss: 0.3477 | Test Accuracy: 83.30%\n",
      "Epoch 05 | Loss: 0.3234 | Test Accuracy: 83.90%\n",
      "Epoch 06 | Loss: 0.3054 | Test Accuracy: 83.20%\n",
      "Epoch 07 | Loss: 0.2894 | Test Accuracy: 83.00%\n",
      "Epoch 08 | Loss: 0.2623 | Test Accuracy: 83.80%\n",
      "Epoch 09 | Loss: 0.2450 | Test Accuracy: 84.00%\n",
      "Epoch 10 | Loss: 0.2260 | Test Accuracy: 83.50%\n",
      "Epoch 11 | Loss: 0.2156 | Test Accuracy: 83.90%\n",
      "Epoch 12 | Loss: 0.1984 | Test Accuracy: 83.60%\n",
      "Epoch 13 | Loss: 0.1836 | Test Accuracy: 83.80%\n",
      "Epoch 14 | Loss: 0.1722 | Test Accuracy: 83.70%\n",
      "Epoch 15 | Loss: 0.1618 | Test Accuracy: 83.30%\n",
      "Epoch 16 | Loss: 0.1494 | Test Accuracy: 83.20%\n",
      "Epoch 17 | Loss: 0.1369 | Test Accuracy: 83.30%\n",
      "Epoch 18 | Loss: 0.1306 | Test Accuracy: 83.10%\n",
      "Epoch 19 | Loss: 0.1219 | Test Accuracy: 83.40%\n",
      "Epoch 20 | Loss: 0.1088 | Test Accuracy: 82.90%\n"
     ]
    }
   ],
   "source": [
    "# instantiate and train 2-layer model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model2 = MLP_2().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):\n",
    "    train_loss = train(model2, train_loader)\n",
    "    acc = evaluate(model2, test_loader)\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {train_loss:.4f} | Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a06fc7be-ec8f-4975-9a84-00f06ec831bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.829\n",
      "Precision: 0.8317982405345697\n",
      "Recall : 0.829\n",
      "F1-score : 0.8297482564498798\n",
      "Confusion Matrix:\n",
      " [[85  1  4  1  0  0  1  2  3  3]\n",
      " [ 3 91  0  1  0  0  0  0  0  5]\n",
      " [ 3  0 75  5  3  4  9  1  0  0]\n",
      " [ 0  0  2 72  2 15  7  2  0  0]\n",
      " [ 2  0  5  7 76  3  1  5  1  0]\n",
      " [ 0  0  6 17  2 70  2  2  1  0]\n",
      " [ 1  0  4  3  1  3 87  1  0  0]\n",
      " [ 1  0  1  4  7  3  0 84  0  0]\n",
      " [ 5  0  1  0  0  0  0  1 93  0]\n",
      " [ 0  2  0  2  0  0  0  0  0 96]]\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = evaluation_loop_full(model2, test_loader, device)\n",
    "evaluate_model(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5514440-fee4-4da7-9e70-1da6c364c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2, \"MLP_2_saved.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d30abb4d-d487-49a5-b1ef-9b67d370fe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.7781 | Test Accuracy: 81.60%\n",
      "Epoch 02 | Loss: 0.4003 | Test Accuracy: 82.70%\n",
      "Epoch 03 | Loss: 0.2906 | Test Accuracy: 82.20%\n",
      "Epoch 04 | Loss: 0.1922 | Test Accuracy: 82.00%\n",
      "Epoch 05 | Loss: 0.1438 | Test Accuracy: 82.20%\n",
      "Epoch 06 | Loss: 0.0881 | Test Accuracy: 83.10%\n",
      "Epoch 07 | Loss: 0.0952 | Test Accuracy: 81.10%\n",
      "Epoch 08 | Loss: 0.0902 | Test Accuracy: 83.10%\n",
      "Epoch 09 | Loss: 0.0781 | Test Accuracy: 81.90%\n",
      "Epoch 10 | Loss: 0.0593 | Test Accuracy: 82.20%\n",
      "Epoch 11 | Loss: 0.0423 | Test Accuracy: 83.10%\n",
      "Epoch 12 | Loss: 0.0510 | Test Accuracy: 82.60%\n",
      "Epoch 13 | Loss: 0.0262 | Test Accuracy: 82.50%\n",
      "Epoch 14 | Loss: 0.0301 | Test Accuracy: 82.90%\n",
      "Epoch 15 | Loss: 0.0287 | Test Accuracy: 82.20%\n",
      "Epoch 16 | Loss: 0.0954 | Test Accuracy: 81.90%\n",
      "Epoch 17 | Loss: 0.0742 | Test Accuracy: 81.90%\n",
      "Epoch 18 | Loss: 0.0912 | Test Accuracy: 82.00%\n",
      "Epoch 19 | Loss: 0.0448 | Test Accuracy: 82.40%\n",
      "Epoch 20 | Loss: 0.0183 | Test Accuracy: 82.00%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model4 = MLP_4().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model4.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):\n",
    "    train_loss = train(model4, train_loader)\n",
    "    acc = evaluate(model4, test_loader)\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {train_loss:.4f} | Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d1fc7ed-abfd-4a68-bf38-ef3220ec0e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "Precision: 0.8273689102003772\n",
      "Recall : 0.8200000000000001\n",
      "F1-score : 0.8204099254681589\n",
      "Confusion Matrix:\n",
      " [[77  1  3  2  0  0  1  1 10  5]\n",
      " [ 1 89  0  1  1  0  1  0  1  6]\n",
      " [ 5  0 70 10  4  2  7  2  0  0]\n",
      " [ 1  0  2 81  3  5  6  1  1  0]\n",
      " [ 3  0  3  8 77  1  2  4  1  1]\n",
      " [ 0  0  6 20  1 68  2  2  1  0]\n",
      " [ 1  0  1  3  1  1 91  1  1  0]\n",
      " [ 0  0  0  4  8  4  0 84  0  0]\n",
      " [ 4  1  1  1  0  0  0  0 90  3]\n",
      " [ 2  1  1  1  0  0  1  0  1 93]]\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = evaluation_loop_full(model4, test_loader, device)\n",
    "evaluate_model(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccfca13f-e260-4b04-8f5e-db4ce76199f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model4, \"MLP_4_saved.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57315645-3a26-4dab-b69b-85c1714b2a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.829\n",
      "Precision: 0.8317982405345697\n",
      "Recall : 0.829\n",
      "F1-score : 0.8297482564498798\n",
      "Confusion Matrix:\n",
      " [[85  1  4  1  0  0  1  2  3  3]\n",
      " [ 3 91  0  1  0  0  0  0  0  5]\n",
      " [ 3  0 75  5  3  4  9  1  0  0]\n",
      " [ 0  0  2 72  2 15  7  2  0  0]\n",
      " [ 2  0  5  7 76  3  1  5  1  0]\n",
      " [ 0  0  6 17  2 70  2  2  1  0]\n",
      " [ 1  0  4  3  1  3 87  1  0  0]\n",
      " [ 1  0  1  4  7  3  0 84  0  0]\n",
      " [ 5  0  1  0  0  0  0  1 93  0]\n",
      " [ 0  2  0  2  0  0  0  0  0 96]]\n"
     ]
    }
   ],
   "source": [
    "#load models\n",
    "\n",
    "model2_loaded = torch.load(\"MLP_2_saved.pth\", weights_only=False, map_location=device)\n",
    "model2_loaded.eval()\n",
    "\n",
    "y_true, y_pred = evaluation_loop_full(model2_loaded, test_loader, device)\n",
    "evaluate_model(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9364f7e-49d0-4f2b-8c4e-65625d00063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.821\n",
      "Precision: 0.8229314736500685\n",
      "Recall : 0.8210000000000001\n",
      "F1-score : 0.8206237678140541\n",
      "Confusion Matrix:\n",
      " [[79  2  6  2  1  0  1  1  4  4]\n",
      " [ 3 90  0  1  0  0  0  0  1  5]\n",
      " [ 5  0 82  5  2  1  4  1  0  0]\n",
      " [ 0  0  3 72  1 13  6  4  1  0]\n",
      " [ 3  0  6  6 70  2  3 10  0  0]\n",
      " [ 1  1  6 13  3 71  3  2  0  0]\n",
      " [ 1  0  3  2  1  3 88  2  0  0]\n",
      " [ 0  0  1  3  3  3  0 90  0  0]\n",
      " [ 5  1  1  1  0  0  0  1 90  1]\n",
      " [ 2  6  0  1  1  0  0  0  1 89]]\n"
     ]
    }
   ],
   "source": [
    " #load models\n",
    "\n",
    "model3_loaded = torch.load(\"MLP_3_saved.pth\", weights_only=False, map_location=device)\n",
    "model3_loaded.eval()\n",
    "\n",
    "y_true, y_pred = evaluation_loop_full(model3_loaded, test_loader, device)\n",
    "evaluate_model(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d34a878-3fdb-45c6-9ecc-2ab19e92df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "Precision: 0.8273689102003772\n",
      "Recall : 0.8200000000000001\n",
      "F1-score : 0.8204099254681589\n",
      "Confusion Matrix:\n",
      " [[77  1  3  2  0  0  1  1 10  5]\n",
      " [ 1 89  0  1  1  0  1  0  1  6]\n",
      " [ 5  0 70 10  4  2  7  2  0  0]\n",
      " [ 1  0  2 81  3  5  6  1  1  0]\n",
      " [ 3  0  3  8 77  1  2  4  1  1]\n",
      " [ 0  0  6 20  1 68  2  2  1  0]\n",
      " [ 1  0  1  3  1  1 91  1  1  0]\n",
      " [ 0  0  0  4  8  4  0 84  0  0]\n",
      " [ 4  1  1  1  0  0  0  0 90  3]\n",
      " [ 2  1  1  1  0  0  1  0  1 93]]\n"
     ]
    }
   ],
   "source": [
    " #load models\n",
    "\n",
    "model4_loaded = torch.load(\"MLP_4_saved.pth\", weights_only=False, map_location=device)\n",
    "model4_loaded.eval()\n",
    "\n",
    "y_true, y_pred = evaluation_loop_full(model4_loaded, test_loader, device)\n",
    "evaluate_model(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d693ab-821e-4c3b-a6da-d46424b52b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
