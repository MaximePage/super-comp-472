{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69764f21-bfea-48f3-b759-0f7722a54436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d39272-ce28-4977-b006-98e75156578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Conv(001, 064, 3, 1, 1)- BatchNorm(064)- ReLU- MaxPool(2, 2)\n",
    "#Conv(064, 128, 3, 1, 1)- BatchNorm(128)- ReLU- MaxPool(2, 2)\n",
    "#Conv(128, 256, 3, 1, 1)- BatchNorm(256)- ReLU\n",
    "#Conv(256, 256, 3, 1, 1)- BatchNorm(256)- ReLU- MaxPool(2, 2)\n",
    "#Conv(256, 512, 3, 1, 1)- BatchNorm(512)- ReLU\n",
    "#Conv(512, 512, 3, 1, 1)- BatchNorm(512)- ReLU- MaxPool(2, 2)\n",
    "#Conv(512, 512, 3, 1, 1)- BatchNorm(512)- ReLU\n",
    "#Conv(512, 512, 3, 1, 1)- BatchNorm(512)- ReLU- MaxPool(2, 2)\n",
    "#Linear(0512, 4096)- ReLU- Dropout(0.5)\n",
    "#Linear(4096, 4096)- ReLU- Dropout(0.5)\n",
    "#Linear(4096, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce386e0d-5894-4e61-b63f-7352645e38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the assignment shows Conv(001, 064, 3, 1, 1)\n",
    "# which \"001\" is the number of input channels which is basically RGB.\n",
    "# which also doesn't make sense because the images we are training and testing on \n",
    "# are all RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d844d0f-c2cf-40e0-bf56-7d489f358a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing for classes\n",
    "def select_class_index(labels, n):\n",
    "    labels = np.array(labels)\n",
    "    selected = []\n",
    "\n",
    "    for c in range(10):\n",
    "        idx = np.where(labels == c)[0][:n]\n",
    "        selected.extend(idx)\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b50a34b-eb49-4f03-96cb-cf53b79c3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar-10 mean and std \n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662ffa66-1d83-4780-af68-e40be6118c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset without transform, to access targets for indexing\n",
    "full_train_set = datasets.CIFAR10(root=\"F:/CIFAR10_Project/data\", train=True, download=True)\n",
    "full_test_set = datasets.CIFAR10(root=\"F:/CIFAR10_Project/data\", train=False, download=True)\n",
    "\n",
    "# returns indices\n",
    "train_indices = select_class_index(full_train_set.targets, 500)  \n",
    "test_indices = select_class_index(full_test_set.targets, 100)   \n",
    "\n",
    "# Create datasets with transform\n",
    "train_set = datasets.CIFAR10(root=\"F:/CIFAR10_Project/data\", train=True, transform=transform)\n",
    "test_set = datasets.CIFAR10(root=\"F:/CIFAR10_Project/data\", train=False, transform=transform)\n",
    "\n",
    "# Wrap in Subset to get only selected indices\n",
    "train_subset = Subset(train_set, train_indices)\n",
    "test_subset = Subset(test_set, test_indices)\n",
    "\n",
    "# Create loaders\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2a53e3-f6e7-4cb5-97c7-d98efbbc88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG11, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1), # <--- project description showed conv(001,..) ?? \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # the fully-connected layers are denoted as Linear(number of input features, number of output features)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c3d6879-586c-4492-96f7-6ac9a88aa9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VGG11().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a567fe3-851e-4299-ab23-e7c41992274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c049b45b-b11b-4ed6-a69a-3f800d3342c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            out = model(X)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9f92df-2dc1-4ec6-bc30-45c60c6b6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_loop_full(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            out = model(X)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05dd6f40-8168-4a0a-a6f9-3736c06f6ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 1.9846 | Test Accuracy: 25.50%\n",
      "Epoch 02 | Loss: 1.7823 | Test Accuracy: 36.80%\n",
      "Epoch 03 | Loss: 1.5969 | Test Accuracy: 38.10%\n",
      "Epoch 04 | Loss: 1.4893 | Test Accuracy: 36.70%\n",
      "Epoch 05 | Loss: 1.4368 | Test Accuracy: 39.00%\n",
      "Epoch 06 | Loss: 1.3267 | Test Accuracy: 37.50%\n",
      "Epoch 07 | Loss: 1.2602 | Test Accuracy: 40.20%\n",
      "Epoch 08 | Loss: 1.1924 | Test Accuracy: 43.30%\n",
      "Epoch 09 | Loss: 1.1332 | Test Accuracy: 48.90%\n",
      "Epoch 10 | Loss: 1.1065 | Test Accuracy: 51.00%\n",
      "Epoch 11 | Loss: 1.0312 | Test Accuracy: 51.20%\n",
      "Epoch 12 | Loss: 1.0326 | Test Accuracy: 47.50%\n",
      "Epoch 13 | Loss: 0.9292 | Test Accuracy: 51.90%\n",
      "Epoch 14 | Loss: 0.9065 | Test Accuracy: 30.40%\n",
      "Epoch 15 | Loss: 0.9035 | Test Accuracy: 55.70%\n",
      "Epoch 16 | Loss: 0.8406 | Test Accuracy: 43.10%\n",
      "Epoch 17 | Loss: 0.8045 | Test Accuracy: 54.30%\n",
      "Epoch 18 | Loss: 0.7280 | Test Accuracy: 43.90%\n",
      "Epoch 19 | Loss: 0.6948 | Test Accuracy: 52.50%\n",
      "Epoch 20 | Loss: 0.6694 | Test Accuracy: 53.80%\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader)\n",
    "    test_acc = evaluate(model, test_loader)\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {train_loss:.4f} | Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# After training, get full predictions and true labels for detailed evaluation\n",
    "true_labels, pred_labels = evaluation_loop_full(model, test_loader, device)\n",
    "#evaluate_model(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae9a83bb-484e-4603-a67a-dc86f95e4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state_dict to a file\n",
    "torch.save(model.state_dict(), \"vgg11_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc87577f-7462-4122-ad59-5707e19949f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.538\n",
      "Precision: 0.6142523448649987\n",
      "Recall : 0.538\n",
      "F1-score : 0.5307327059627751\n",
      "Confusion Matrix:\n",
      " [[43  3  7  7  3  5  1  4 10 17]\n",
      " [ 0 36  1  0  0  0  0  2  0 61]\n",
      " [ 6  0 31 15 16 20  5  6  0  1]\n",
      " [ 0  0  4 39  4 44  1  4  0  4]\n",
      " [ 0  0  2  7 45 13  0 30  0  3]\n",
      " [ 0  0  2 13  2 74  1  8  0  0]\n",
      " [ 0  0  2 18 19 16 36  7  0  2]\n",
      " [ 0  0  0  1  0 16  0 82  0  1]\n",
      " [ 5  3  0  6  3  1  0  0 62 20]\n",
      " [ 0  2  0  2  0  1  0  1  4 90]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='macro'))\n",
    "    print(\"Recall :\", recall_score(y_true, y_pred, average='macro'))\n",
    "    print(\"F1-score :\", f1_score(y_true, y_pred, average='macro'))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "evaluate_model(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3d65d-611d-4669-89fd-a7a50de5d94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
